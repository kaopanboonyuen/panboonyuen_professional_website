---
title: "Lecture 08 â€” Evaluation Metrics"
date: "2025-12-30"
type: book
weight: 80
math: true
---

<!--more-->

{{< icon name="clock" pack="fas" >}} ~3 hours (core evaluation & reasoning lecture)

---

## ğŸ“ Why Evaluation Metrics Matter (Truth First)

A dangerous myth:

> â€œIf accuracy is high, the model is good.â€

Reality:

> **Wrong metric = wrong conclusion = real-world harm**

Evaluation metrics define:
- what â€œsuccessâ€ means
- what the model optimizes for
- how humans trust AI

---

## ğŸ§  One Sentence That Explains Metrics

> **Metrics are how humans translate values into numbers.**

Different problems â†’ different values â†’ different metrics.

---

## ğŸ§ª A Running Example (Very Important)

Imagine a **disease detection system** ğŸ¥

- Disease rate: 1%
- Healthy people: 99%

This will destroy naive accuracy.

---

# ğŸ”¹ PART I â€” Classification Metrics

---

## ğŸ§© Confusion Matrix (The Foundation)

Everything starts here.

|                | Predicted Positive | Predicted Negative |
|----------------|-------------------|-------------------|
| **Actual Positive** | TP (True Positive) | FN (False Negative) |
| **Actual Negative** | FP (False Positive) | TN (True Negative) |

ğŸ‘‰ Every metric is built from these four numbers.

---

## ğŸ¯ Accuracy (The Most Misused Metric)

### ğŸ“ Formula

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$

### ğŸ˜„ Example

Out of 1000 people:
- 990 healthy
- 10 sick

Model predicts **everyone healthy**.

Accuracy:
$$
= \frac{990}{1000} = 99\%
$$

ğŸ‰ Looks amazing  
ğŸ’€ Completely useless

---

## âŒ Why Accuracy Fails

- ignores class imbalance
- ignores cost of mistakes
- rewards lazy models

---

## ğŸ¯ Precision (How Careful Are You?)

### ğŸ“ Formula

$$
Precision = \frac{TP}{TP + FP}
$$

### ğŸ§  Meaning

> When the model says â€œpositiveâ€, how often is it correct?

---

### ğŸ˜„ Example (Spam Filter)

- Marked 10 emails as spam
- 8 were actually spam

$$
Precision = \frac{8}{10} = 0.8
$$

High precision = few false alarms ğŸ“©ğŸš«

---

## ğŸ¯ Recall (How Much Did You Catch?)

### ğŸ“ Formula

$$
Recall = \frac{TP}{TP + FN}
$$

### ğŸ§  Meaning

> Of all real positives, how many did we find?

---

### ğŸ˜„ Example (Medical Test)

- 10 sick patients
- Found 7

$$
Recall = \frac{7}{10} = 0.7
$$

Low recall = missed patients ğŸ˜¬

---

## âš–ï¸ Precision vs Recall (Classic Tradeoff)

| Metric | Focus |
|------|------|
| Precision | Avoid false positives |
| Recall | Avoid false negatives |

Medical diagnosis â†’ high recall  
Spam filter â†’ high precision

---

## ğŸ¯ F1 Score (The Balance)

### ğŸ“ Formula

$$
F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
$$

### ğŸ§  Meaning

> One number that balances both.

---

### ğŸ˜„ Example

Precision = 0.8  
Recall = 0.6  

$$
F1 = 2 \cdot \frac{0.8 \cdot 0.6}{1.4} \approx 0.69
$$

Used when:
- classes are imbalanced
- both errors matter

---

# ğŸ”¹ PART II â€” Regression Metrics

---

## ğŸ¯ Mean Absolute Error (MAE)

### ğŸ“ Formula

$$
MAE = \frac{1}{n} \sum |y - \hat{y}|
$$

### ğŸ§  Meaning

> Average absolute mistake.

---

### ğŸ˜„ Example

True prices: `[100, 200]`  
Predicted: `[90, 210]`

Errors:
- |100âˆ’90| = 10
- |200âˆ’210| = 10

$$
MAE = \frac{20}{2} = 10
$$

Easy to understand ğŸ‘

---

## ğŸ¯ Mean Squared Error (MSE)

### ğŸ“ Formula

$$
MSE = \frac{1}{n} \sum (y - \hat{y})^2
$$

### ğŸ§  Meaning

> Punishes large mistakes more.

---

### ğŸ˜„ Example

Errors: `[10, 10]`  
Squares: `[100, 100]`

$$
MSE = 100
$$

Used when big errors are very bad.

---

## ğŸ¯ Root Mean Squared Error (RMSE)

### ğŸ“ Formula

$$
RMSE = \sqrt{MSE}
$$

### ğŸ§  Meaning

Same unit as target variable.

If RMSE = 10 â†’ â€œaverage error â‰ˆ 10 unitsâ€

---

# ğŸ”¹ PART III â€” NLP Metrics (Language Is Hard)

---

## ğŸ§  Why NLP Metrics Are Tricky

Language has:
- multiple correct answers
- style differences
- synonyms

Exact matching fails.

---

## âœï¸ BLEU Score (Translation)

Measures:
> Overlap of n-grams between prediction and reference.

### ğŸ“ Simplified Idea

More shared phrases â†’ higher BLEU.

---

### ğŸ˜„ Example

Reference:
> â€œAI changes the worldâ€

Prediction:
> â€œAI transforms the worldâ€

High BLEU (similar meaning).

---

## ğŸ“„ ROUGE (Summarization)

Measures:
- overlap of words
- overlap of phrases

Used in:
- summarization
- report generation

---

## âš ï¸ Important Truth About NLP Metrics

High BLEU/ROUGE â‰  good answer.

Human evaluation still matters.

ChatGPT is trained with:
- cross-entropy (math)
- human feedback (values)

---

# ğŸ”¹ PART IV â€” Metrics in the Real World

---

## ğŸ¥ Medical AI
- prioritize recall
- false negatives are dangerous

## ğŸ“© Spam Detection
- prioritize precision
- false positives annoy users

## ğŸš— Self-Driving
- safety-critical metrics
- worst-case analysis

## ğŸ¤– ChatGPT
- fluency
- helpfulness
- harmlessness
- alignment (human judgment)

---

## ğŸ§  Choosing the Right Metric (Golden Rule)

Ask:
1. What mistake hurts more?
2. Who pays the cost?
3. Is data balanced?

Metrics encode **ethics**.

---

## ğŸŒ Final Big Insight

> **AI does not know what is â€œgood.â€  
Metrics tell it what to care about.**

Choose wisely.

---

## â“ Final Reflection

{{< spoiler text="If you optimize the wrong metric, can AI become dangerous?" >}}
Yes â€” optimization without wisdom is risk.
{{< /spoiler >}}
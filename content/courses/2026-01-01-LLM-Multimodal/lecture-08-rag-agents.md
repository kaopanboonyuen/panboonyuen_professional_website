---
title: "Lecture 08 â€” RAG, AI Agents & Agentic Multimodal Systems"
date: "2026-01-01"
type: book
weight: 80
---

<!--more-->

{{< icon name="clock" pack="fas" >}} ~4â€“6 hours (modern AI systems design)

---

## ðŸ§  Why This Lecture Changes Everything

> **Models are not intelligent alone.  
Systems are.**

RAG and AI Agents represent a shift:
- âŒ From static models  
- âœ… To *interactive, grounded, tool-using intelligence*

This lecture connects:
- LLMs
- Multimodality
- Memory
- Tools
- Reasoning
- Real-world deployment

---

## ðŸ§© What Is Retrieval-Augmented Generation (RAG)?

**RAG = Knowledge + Reasoning**

Instead of forcing the model to:
- memorize everything
- hallucinate confidently

We let it:
1. Retrieve relevant information
2. Reason over it
3. Generate grounded answers

---

## ðŸ” Classical LLM vs RAG

| Aspect | Classical LLM | RAG |
|----|----|----|
| Knowledge | Frozen | Dynamic |
| Hallucination | High | Lower |
| Updates | Retrain | Re-index |
| Traceability | Poor | Strong |
| Enterprise-ready | âŒ | âœ… |

> **RAG turns LLMs into â€œopen-book thinkers.â€**

---

## ðŸ§  Core RAG Pipeline

```

User Query
â†“
Embedding
â†“
Retriever (Vector DB)
â†“
Relevant Context
â†“
LLM Reasoning
â†“
Answer + Citations

````

---

## ðŸ“¦ What Can Be Retrieved?

- ðŸ“„ Documents
- ðŸ–¼ Images
- ðŸŽ¥ Videos
- ðŸ§¾ Tables
- ðŸ“Š Logs
- ðŸ§  Memories (Agent state)

> Multimodal RAG = **cross-modal retrieval + reasoning**

---

## ðŸ§  Embeddings: The Heart of RAG

Embedding models map meaning â†’ vectors.

Examples:
- Text: sentence-transformers
- Image: CLIP
- Video: InternVideo
- Document: Layout-aware embeddings

> **Good retrieval beats bigger models.**

---

## ðŸ Python: Minimal RAG Example

```python
query = "What is transformer attention?"

q_emb = embedder.encode(query)
docs = vector_db.search(q_emb, top_k=5)

context = "\n".join(docs)

answer = llm.generate(
    prompt=f"Answer using the context below:\n{context}\n\nQuestion:{query}"
)
````

---

## âš ï¸ Common RAG Failure Modes

* Retrieving irrelevant chunks
* Context too long
* Context ignored
* Conflicting documents
* Over-trusting retrieved text

Mitigation:

* Chunking strategy
* Reranking
* Instruction tuning
* Answer verification

---

## ðŸ¤– What Is an AI Agent?

> **An agent is an LLM that can act.**

Agent abilities:

* Decide next action
* Use tools
* Store memory
* Observe outcomes
* Iterate

---

## ðŸ§  Agent Loop (Canonical)

```
Observe â†’ Think â†’ Act â†’ Reflect â†’ Repeat
```

This is **not prompting** â€” it is **control flow**.

---

## ðŸ§© Agent Components

| Component | Role            |
| --------- | --------------- |
| LLM       | Reasoning       |
| Memory    | State           |
| Tools     | Actions         |
| Planner   | Decomposition   |
| Executor  | Tool calling    |
| Critic    | Self-evaluation |

---

## ðŸ›  Tools an Agent Can Use

* Search engines
* Databases
* Code execution
* APIs
* OCR
* Vision models
* File systems

> **Tools extend intelligence beyond tokens.**

---

## ðŸ Python: Simple Agent Skeleton

```python
while not task_done:
    thought = llm.think(state)
    action = planner.select(thought)
    result = tools.run(action)
    state.update(result)
```

---

## ðŸ§  What Is Agentic AI?

**Agentic AI** means:

* Long-horizon goals
* Autonomous planning
* Self-correction
* Tool orchestration
* Memory persistence

Examples:

* Research agents
* Coding agents
* Multimodal assistants
* Auto-analysts

---

## ðŸ”— RAG + Agents = Power

RAG answers questions.
Agents **decide what to retrieve and why**.

```
Agent
  â”œâ”€â”€ Query RAG
  â”œâ”€â”€ Verify answer
  â”œâ”€â”€ Ask follow-up
  â”œâ”€â”€ Use tools
  â””â”€â”€ Deliver result
```

> This is how **real AI systems are built today**.

---

## ðŸ§  Multimodal Agent Example

Task:

> â€œAnalyze this traffic video and explain why the accident occurred.â€

Agent flow:

1. Extract video frames
2. Retrieve traffic rules (RAG)
3. Detect events
4. Reason causality
5. Generate explanation

---

## âš ï¸ Risks of Agentic Systems

* Tool misuse
* Infinite loops
* Overconfidence
* Hidden failures
* Alignment drift

Mitigation:

* Guardrails
* Cost limits
* Human approval
* Logging
* Evaluation

---

## ðŸ“ Evaluating RAG & Agents

### RAG Evaluation

* Retrieval recall
* Faithfulness
* Answer correctness
* Citation accuracy

### Agent Evaluation

* Task success rate
* Steps efficiency
* Error recovery
* Human satisfaction

---

## ðŸ§  Research Insight

> Intelligence is no longer **inside the model**
> It is **distributed across systems**

The future:

* Smaller models
* Better retrieval
* Smarter agents
* Human oversight

---

## ðŸ§ª Student Knowledge Check (Hidden)

### Q1 â€” Objective

What problem does RAG primarily solve?

{{< spoiler text="Answer" >}}
Hallucination and static knowledge.
{{< /spoiler >}}

---

### Q2 â€” MCQ

Which is NOT a core agent component?

A. Memory
B. Planner
C. Tool interface
D. Dataset labeler

{{< spoiler text="Answer" >}}
D. Dataset labeler
{{< /spoiler >}}

---

### Q3 â€” MCQ

Why combine RAG with agents?

A. Reduce cost
B. Improve UI
C. Enable decision-driven retrieval
D. Increase model size

{{< spoiler text="Answer" >}}
C. Enable decision-driven retrieval
{{< /spoiler >}}

---

### Q4 â€” Objective

What is agentic AI?

{{< spoiler text="Answer" >}}
AI systems that plan, act, use tools, and self-correct toward goals.
{{< /spoiler >}}

---

### Q5 â€” Objective

Why is human oversight important for agents?

{{< spoiler text="Answer" >}}
To prevent unsafe, incorrect, or misaligned actions.
{{< /spoiler >}}

---

## ðŸŒ± Final Reflection

{{< spoiler text="If AI agents can act autonomously, what must humans always control?" >}}
Goals, values, boundaries, and accountability.
{{< /spoiler >}}

---

## âœ… Key Takeaways

* RAG grounds intelligence
* Agents enable action
* Agentic AI is system-level intelligence
* Multimodal agents are the future
* Humans must remain in the loop

---